# -*- coding: utf-8 -*-
"""
Created on Mon Feb  8 09:54:04 2021

@author: ander428
"""
#%%
import pandas as pd
import geopandas as gpd
import os
import boto3
import s3fs

CURR_DIR = os.path.dirname(os.path.realpath(__file__))
os.chdir(CURR_DIR)
from s3_secret import s3_access_key_id, s3_secret_access_key

#%%
class s3_api(object):
    def __init__(self):
        self.client = self.get_new_client()
        self.bucket = self.get_new_bucket()
        self.root = os.getcwd()
        
    def set_root(self, root):
        self.root = root
    
    def get_new_client(self):
        client = boto3.client(
            's3',
            aws_access_key_id = s3_access_key_id,
            aws_secret_access_key = s3_secret_access_key,
            region_name = 'us-west-1'
        )
        return client
    
    def get_new_bucket(self):
        resource = boto3.resource(
            's3',
            aws_access_key_id = s3_access_key_id,
            aws_secret_access_key = s3_secret_access_key,
            region_name = 'us-west-1'
        )
        return resource.Bucket("vulnerabilitymapping")
    
    def list_buckets(self):
        return self.client.list_buckets()['Buckets']
    
    def list_bucket_keys(self):
        keys = []
        for s3_file in self.bucket.objects.all():
            keys.append(s3_file.key)
        return keys
    
    def get_bucket_df(self, key):
        obj = self.client.get_object(
            Bucket = "vulnerabilitymapping",
            Key = key
        )
            
        # Read data from the S3 object
        return pd.read_csv(obj['Body'])

    def get_bucket_geoDF(self, key, rb = True):
        s3 = s3fs.S3FileSystem(key=s3_access_key_id, secret=s3_secret_access_key)
        read_val = 'rb' if rb else 'r'
        with s3.open(f"s3://vulnerabilitymapping/{key}", read_val) as f:
            return gpd.read_file(f)
        
    def get_bucket_shp(self, remote_dir, local_dir):
        if not os.path.isdir(local_dir):
            os.makedirs(local_dir)
            print("Created local directory.")
        
        prev_dir = os.getcwd()
        os.chdir(local_dir)
        
        print("Downloading files locally...")
        for obj in self.bucket.objects.filter(Prefix = remote_dir):
            # account for leading slash
            if obj.key == remote_dir or obj.key[:-1] == remote_dir:
                continue
            
            obj_name_lst = obj.key.split("/")
            obj_name = obj_name_lst[len(obj_name_lst)-1]
            self.bucket.download_file(obj.key, obj_name)
        
        print("Loading files into Python...")
        shp = gpd.read_file(obj_name)
        os.chdir(prev_dir)
        print("Done.")
        return shp
        
        
    def write_csv(self, df, file_path, file_name):
        s3 = s3fs.S3FileSystem(key=s3_access_key_id, secret=s3_secret_access_key)
        with s3.open(f"s3://vulnerabilitymapping/{file_path}/{file_name}", 'wb', encoding="utf-8") as f:
            df.to_csv(f)
    
    def write_GeoJSON(self, gdf, file_path, file_name):
        s3 = s3fs.S3FileSystem(key=s3_access_key_id, secret=s3_secret_access_key)
        with s3.open(f"s3://vulnerabilitymapping/{file_path}/{file_name}", 'wb', encoding="utf-8") as f:
            gdf.to_file(f, driver='GeoJSON')
    
    def write_shp(self, gdf, file_path, file_name):
        # remove .shp in name if given
        if ".shp" in file_name:
            file_name = file_name[:-4]
        
        # create temp folder to sync with s3
        CURR_DIR = self.root
        if not os.path.isdir(os.path.join(CURR_DIR, "data", "temp")):
            os.mkdir(os.path.join(CURR_DIR, "data", "temp"))
        if not os.path.isdir(os.path.join(CURR_DIR, "data", "temp", file_name)):
            os.mkdir(os.path.join(CURR_DIR, "data", "temp", file_name))
        
        os.chdir(os.path.join(CURR_DIR, "data", "temp", file_name))

        
        print("Generating local shp files...")
        gdf.to_file(driver = 'ESRI Shapefile', filename= os.path.join(os.getcwd(), f"{file_name}.shp"))
        
        print("Uploading to s3...")
        for file in os.listdir(os.getcwd()):
            with open(os.path.join(os.getcwd(), file), "rb") as f:
                self.client.upload_fileobj(f, "vulnerabilitymapping", f"{file_path}/{file}")
                
        print("Done.")
    
    def get_client(self):
        return self.client
    
